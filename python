import numpy as np
import cv2 as cv
import argparse
import matplotlib.pyplot as plt
import xlsxwriter
from openpyxl import load_workbook
from scipy.signal import savgol_filter
from pandas import read_csv
import math
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

cap = cv.VideoCapture("D:/optical flow/video/20220725-3_self.mp4")

#20220428-5_self.mp4 20220428-1_self.mp4 0328self-2.mp4

# ShiTomasi 角點檢測的參數
feature_params = dict( maxCorners = 100, #角點數
                       qualityLevel = 0.8, #質量等級
                       minDistance = 3, #角點之間最小距離
                       blockSize = 3 )

# 光流的參數
lk_params = dict( winSize  = (15, 15),
                  maxLevel = 2,
                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))

# Create some random colors
color = np.random.randint(0, 255, (100, 3))

# 取第一幀並在其中找到角落
ret, old_frame = cap.read()
old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)
p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)

# Create a mask image for drawing purposes
mask = np.zeros_like(old_frame)

p0array=[]
resultarray=[]
testpnumber = 0
clarityresultarray=[]
while(1):
    ret, frame = cap.read()
    if not ret:
        print('No frames grabbed!')
        break

    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)

    # 計算光流
    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)

    # 選擇點
    if p1 is not None:
        good_new = p1[st==1]
        good_old = p0[st==1]

    # 畫軌跡
    for i, (new, old) in enumerate(zip(good_new, good_old)):
        a, b = new.ravel()
        c, d = old.ravel()
        mask = cv.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)
        frame = cv.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)
        
    img = cv.add(frame, mask)

    cv.imshow('frame', img)
    k = cv.waitKey(1) & 0xff
    if k == 27:
        break
    #光流法(須改)
    p0array=np.append(p0array,p0)
    if testpnumber == 0:
        p0number=p0.shape[0] * p0.shape[2]
        testpnumber +=1
        
    for i in range(p0number):
        if p0array.shape[0] % p0number != 0:
            p0array=np.append(p0array,[0])    
    p0array=p0array.reshape(-1,p0number)
    
    # 更新上一幀和之前的點
    old_gray = frame_gray.copy()
    p0 = good_new.reshape(-1, 1, 2)
    #清晰度
    clarityresult=cv.Laplacian(frame_gray,cv.CV_64F).var()
    clarityresultarray.append(clarityresult)
    
#cornernumber=int(p0array.shape[1]/2) 
frame_number=p0array.shape[0] 

#畫圖
n0array=[]
n1array=[]

fig=plt.figure()

for i in range(0,frame_number-1):
    n0 = p0array[i+1,0]-p0array[i,0]
    n0array.append(n0)
    n1 = p0array[i+1,1]-p0array[i,1]
    n1array.append(n1)

xsmootharray = savgol_filter(n0array,21,3)
ysmootharray = savgol_filter(n1array,21,3)
smooth_clarityresultarray = savgol_filter(clarityresultarray,21,3)

ax1=fig.add_subplot(2,3,1)
ax2=fig.add_subplot(2,3,2)



'''
N0,= plt.plot(xsmootharray)
N1,= plt.plot(ysmootharray)

'''

N0,= ax1.plot(xsmootharray)
N1,= ax1.plot(ysmootharray)
b1,= ax2.plot(smooth_clarityresultarray)


fig.savefig('testnow2.png')

writer = xlsxwriter.Workbook('savepichture2.xlsx')
sheet = writer.add_worksheet('test')

sheet.write_column('A1', xsmootharray)
sheet.write_column('B1', ysmootharray)
sheet.write_column('C1', smooth_clarityresultarray)

###np.savetxt('xsmootharray.csv', xsmootharray, delimiter=',')
###np.savetxt('ysmootharray.csv',ysmootharray, delimiter=',')
###np.savetxt('smooth_clarityresultarray.csv', smooth_clarityresultarray, delimiter=',')

#分解判斷A,B,C,D 
#find A
ma=np.array([])
nowframe = 10

while (nowframe < len(ysmootharray)-10):
    flagy=1
    flagx=1
    directiony=1
    directionx=1
    range_xy=1
    clarityflag=1
    for y in range(2):
        if ysmootharray[nowframe] < -9 or ysmootharray[nowframe] > 7 : #5
            flagy=0
        if ysmootharray[nowframe+y]-ysmootharray[nowframe] < 0 and ysmootharray[nowframe]- ysmootharray[nowframe-y] < 0:
            directiony=0
    for x in range(2):
        if xsmootharray[nowframe] < -9 or xsmootharray[nowframe] > 7 :
            flagx=0
        if xsmootharray[nowframe+x]-xsmootharray[nowframe] > 0 :
            directionx=0
        if xsmootharray[nowframe]- xsmootharray[nowframe-x] > 0:
            directionx=0
    if xsmootharray[nowframe] - ysmootharray[nowframe] > 2.7:
        range_xy=0
    if smooth_clarityresultarray[nowframe-1] > smooth_clarityresultarray[nowframe]  and  smooth_clarityresultarray[nowframe+1] > smooth_clarityresultarray[nowframe]:
        clarityflag=0
    if flagy==1 and flagx ==1 and directionx==1 and directiony==1 and clarityflag==1 and range_xy==1:
        ma=np.append(ma,nowframe)
        nowframe+=60
    else:
        nowframe+=1

#find B
mb=np.array([])
nowframe = int(ma[0])

while (nowframe < len(ysmootharray)-10):
    flagx=1
    flagy=1
    directiony=1
    directionx=1
    clarityflag=1
    for y in range(3):
        if ysmootharray[nowframe+y] - ysmootharray[nowframe] > 0 and ysmootharray[nowframe] - ysmootharray[nowframe-y] > 0:
            directiony=0
    for x in range(2):
        if xsmootharray[nowframe] > 0:
            directionx=0
        if xsmootharray[nowframe+x] - xsmootharray[nowframe] < 0:
            directionx=0
        if xsmootharray[nowframe] - xsmootharray[nowframe-x] > 0:
            directionx=0
    if smooth_clarityresultarray[nowframe-1] < smooth_clarityresultarray[nowframe]  and  smooth_clarityresultarray[nowframe+1] < smooth_clarityresultarray[nowframe]:
        clarityflag=0
    if flagy==1 and flagx ==1 and directionx==1 and directiony==1 and clarityflag==1:
        mb=np.append(mb,nowframe)
        nowframe+=60
    else:
        nowframe+=1

#find C
mc=np.array([])
nowframe = int(mb[0])

while (nowframe < len(ysmootharray)-10):
    flagx=1
    flagy=1
    directiony=1
    directionx=1
    range_xy=1
    clarityflag=1
    for y in range(4):
        #if ysmootharray[nowframe] > 1:
            #flagy=0
        if ysmootharray[nowframe+y]-ysmootharray[nowframe] > 0 and ysmootharray[nowframe]- ysmootharray[nowframe-y] > 0:
            directiony=0
    for x in range(4):
        #if xsmootharray[nowframe] > 1:
            #flagx=0
        if xsmootharray[nowframe+x]-xsmootharray[nowframe] < 0  :
            directionx=0  
        if xsmootharray[nowframe]- xsmootharray[nowframe-x] < 0 :
            directionx=0
    if ysmootharray[nowframe] - xsmootharray[nowframe] > 3:
        range_xy=0
    if smooth_clarityresultarray[nowframe-1] > smooth_clarityresultarray[nowframe]  and  smooth_clarityresultarray[nowframe+1] > smooth_clarityresultarray[nowframe]:
        clarityflag=0
    if flagy==1 and flagx ==1 and directionx==1 and directiony==1 and range_xy==1 and clarityflag==1:
        mc=np.append(mc,nowframe)
        nowframe+=60
    else:
        nowframe+=1

#find D
md=np.array([])
nowframe = int(mc[0])

while (nowframe < len(ysmootharray)-10):
    flagy=1
    flagx=1
    directiony=1
    directionx=1
    clarityflag=1
    for y in range(2):
        #if ysmootharray[nowframe] < -2:
           # flagy=0
        if ysmootharray[nowframe+y]-ysmootharray[nowframe] > 0 and ysmootharray[nowframe]- ysmootharray[nowframe-y] > 0:
            directiony=0
    for x in range(4):
        if xsmootharray[nowframe] < 5:
            flagx=0
        if xsmootharray[nowframe+x]-xsmootharray[nowframe] > 0 :
            directionx=0
        if xsmootharray[nowframe]- xsmootharray[nowframe-x] < 0:
            directionx=0
        if smooth_clarityresultarray[nowframe-1] > smooth_clarityresultarray[nowframe]  and  smooth_clarityresultarray[nowframe+1] > smooth_clarityresultarray[nowframe]:
            clarityflag=0
    if flagy==1 and flagx==1 and directionx==1 and directiony==1 and clarityflag==1:
        md=np.append(md,nowframe)
        nowframe+=60
    else:
        nowframe+=1

writer.close()

cv.destroyAllWindows()

#determine the time parameters
#步頻(steps/min)：單位分鐘內行走的步伐數量
print("\n*******************")
print("time parameters \n")
'''
# 產生 (X, Y) 資料集, Y 是下一期的乘客數
def create_dataset(dataset, look_back=1):
	dataX, dataY = [], []
	for i in range(len(dataset)-look_back-1):
		a = dataset[i:(i+look_back), 0]
		dataX.append(a)
		dataY.append(dataset[i + look_back, 0])
	return np.array(dataX), np.array(dataY)
    
# fix random seed for reproducibility
np.random.seed(7)##生成指定隨機數


# 載入訓練資料
dataframe = read_csv('xsmootharray.csv', usecols=[0], engine='python')
dataset = dataframe.values##dataframe的值
dataset = dataset.astype('float32')##32為精度,astype:對數據類型進行轉換
# 正規化(normalize) 資料，使資料值介於[0, 1]
######################################################
scaler = MinMaxScaler(feature_range=(0, 1))##最小最大值標準化
dataset = scaler.fit_transform(dataset)
#########################################################



# 2/3 資料為訓練資料， 1/3 資料為測試資料#######################################################
train_size = int(len(dataset) * 0.67)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]
#############################################################################################
# 產生 (X, Y) 資料集, Y 是下一期的乘客數(reshape into X=t and Y=t+1)
##改成自己的資料之後就變成Y是下一期的清晰度
look_back = 1
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)
# reshape input to be [samples, time steps, features]
trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

# 建立及訓練 LSTM 模型
model = Sequential()##建立簡單的線性執行模型
model.add(LSTM(4, input_shape=(1, look_back)))##input_shape=(n_step,n_feature)==>input_shape=(幾步，幾個特徵)
model.add(Dense(1))##變成像是y=x1
model.compile(loss='mean_squared_error', optimizer='adam')##loss為損失函數，optimizer,調整參數，使loss減少
model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)##裡面的trainX,trainY為指定訓練資料

# 預測
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)

# 回復預測資料值為原始數據的規模
trainPredict = scaler.inverse_transform(trainPredict)
trainY = scaler.inverse_transform([trainY])
testPredict = scaler.inverse_transform(testPredict)
testY = scaler.inverse_transform([testY])

# calculate 均方根誤差(root mean squared error)
trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))
print('Test Score: %.2f RMSE' % (testScore))

##均方根誤差為說明樣本的離散程度，值越小越好。。表示訓練集跟測試集之間的樣本標準差






# 畫訓練資料趨勢圖
# shift train predictions for plotting
trainPredictPlot = np.empty_like(dataset)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict

# 畫測試資料趨勢圖
# shift test predictions for plotting
testPredictPlot = np.empty_like(dataset)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict

# 畫原始資料趨勢圖
# plot baseline and predictions
ax3=fig.add_subplot(2,3,3)
p2,= plt.plot(scaler.inverse_transform(dataset))
p2,=plt.plot(trainPredictPlot)
p2,=plt.plot(testPredictPlot)
'''


'''
dataframe = read_csv('ysmootharray.csv', usecols=[0], engine='python')
dataset = dataframe.values##dataframe的值
dataset = dataset.astype('float32')##32為精度,astype:對數據類型進行轉換
# 正規化(normalize) 資料，使資料值介於[0, 1]
######################################################
scaler = MinMaxScaler(feature_range=(0, 1))##最小最大值標準化
dataset = scaler.fit_transform(dataset)
#########################################################



# 2/3 資料為訓練資料， 1/3 資料為測試資料#######################################################
train_size = int(len(dataset) * 0.67)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]
#############################################################################################
# 產生 (X, Y) 資料集, Y 是下一期的乘客數(reshape into X=t and Y=t+1)
##改成自己的資料之後就變成Y是下一期的清晰度
look_back = 1
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)
# reshape input to be [samples, time steps, features]
trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

# 建立及訓練 LSTM 模型
model = Sequential()##建立簡單的線性執行模型
model.add(LSTM(4, input_shape=(1, look_back)))##input_shape=(n_step,n_feature)==>input_shape=(幾步，幾個特徵)
model.add(Dense(1))##變成像是y=x1
model.compile(loss='mean_squared_error', optimizer='adam')##loss為損失函數，optimizer,調整參數，使loss減少
model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)##裡面的trainX,trainY為指定訓練資料

# 預測
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)

# 回復預測資料值為原始數據的規模
trainPredict = scaler.inverse_transform(trainPredict)
trainY = scaler.inverse_transform([trainY])
testPredict = scaler.inverse_transform(testPredict)
testY = scaler.inverse_transform([testY])

# calculate 均方根誤差(root mean squared error)
trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))
print('Test Score: %.2f RMSE' % (testScore))

##均方根誤差為說明樣本的離散程度，值越小越好。。表示訓練集跟測試集之間的樣本標準差






# 畫訓練資料趨勢圖
# shift train predictions for plotting
trainPredictPlot = np.empty_like(dataset)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict

# 畫測試資料趨勢圖
# shift test predictions for plotting
testPredictPlot = np.empty_like(dataset)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict

# 畫原始資料趨勢圖
# plot baseline and predictions
ax4=fig.add_subplot(2,3,4)
p3,= plt.plot(scaler.inverse_transform(dataset))
p3,=plt.plot(trainPredictPlot)
p3,=plt.plot(testPredictPlot)


dataframe = read_csv('smooth_clarityresultarray.csv', usecols=[0], engine='python')
dataset = dataframe.values##dataframe的值
dataset = dataset.astype('float32')##32為精度,astype:對數據類型進行轉換
# 正規化(normalize) 資料，使資料值介於[0, 1]
######################################################
scaler = MinMaxScaler(feature_range=(0, 1))##最小最大值標準化
dataset = scaler.fit_transform(dataset)
#########################################################



# 2/3 資料為訓練資料， 1/3 資料為測試資料#######################################################
train_size = int(len(dataset) * 0.67)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]
#############################################################################################
# 產生 (X, Y) 資料集, Y 是下一期的乘客數(reshape into X=t and Y=t+1)
##改成自己的資料之後就變成Y是下一期的清晰度
look_back = 1
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)
# reshape input to be [samples, time steps, features]
trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

# 建立及訓練 LSTM 模型
model = Sequential()##建立簡單的線性執行模型
model.add(LSTM(4, input_shape=(1, look_back)))##input_shape=(n_step,n_feature)==>input_shape=(幾步，幾個特徵)
model.add(Dense(1))##變成像是y=x1
model.compile(loss='mean_squared_error', optimizer='adam')##loss為損失函數，optimizer,調整參數，使loss減少
model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)##裡面的trainX,trainY為指定訓練資料

# 預測
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)

# 回復預測資料值為原始數據的規模
trainPredict = scaler.inverse_transform(trainPredict)
trainY = scaler.inverse_transform([trainY])
testPredict = scaler.inverse_transform(testPredict)
testY = scaler.inverse_transform([testY])

# calculate 均方根誤差(root mean squared error)
trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))
print('Test Score: %.2f RMSE' % (testScore))

##均方根誤差為說明樣本的離散程度，值越小越好。。表示訓練集跟測試集之間的樣本標準差






# 畫訓練資料趨勢圖
# shift train predictions for plotting
trainPredictPlot = np.empty_like(dataset)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict

# 畫測試資料趨勢圖
# shift test predictions for plotting
testPredictPlot = np.empty_like(dataset)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict

# 畫原始資料趨勢圖
# plot baseline and predictions
ax5=fig.add_subplot(2,3,5)
p4,= plt.plot(scaler.inverse_transform(dataset))
p4,=plt.plot(trainPredictPlot)
p4,=plt.plot(testPredictPlot)
'''
